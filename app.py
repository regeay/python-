import gradio as gr
import os
from search import search  # å¯¼å…¥æœç´¢æ¨¡å—
from chat import  chat # å¯¼å…¥æµå¼èŠå¤©
from fetch import fetch # å¯¼å…¥ç½‘é¡µæ€»ç»“
from pdf import * # å¯¼å…¥æ–‡ä»¶èŠå¤©
from image_generate import image_generate # å¯¼å…¥å›¾ç‰‡ç”Ÿæˆ


messages = []
history = []
current_file_text = "" # å­˜å‚¨å½“å‰ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹
file_processed = False # è®°å½•å½“å‰æ–‡ä»¶æ˜¯å¦éœ€è¦å¤„ç†

def add_text(history, text):
    # ç”¨æˆ·è¾“å…¥ -> history
    history = history + [(text, None)]
    # æ¨¡å‹æ¶ˆæ¯è®°å½• -> messages
    messages.append({"role": "user", "content": text})
    return history, gr.update(value="", interactive=False)

def add_file(history, file):
    global current_file_text, file_processed
    if file.name.lower().endswith('.txt'):
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file, 'r', encoding='utf-8') as f:
                current_file_text = f.read().strip()
            messages.append({"role": "user", "content": (file.name,)})
            
            # è¡¨æ˜å½“å‰æ–‡ä»¶éœ€è¦å¤„ç†å¹¶è¿”å›
            file_processed = True
            history = history + [((file.name,), None)]
            return history
    
        except Exception as e:
            return history + [((file.name,), f"Error: {str(e)}")]
    else:
        return history + [((file.name,), "Only .txt files supported")]

   

def bot(history):
    global current_file_text, file_processed
    user_input = messages[-1]["content"]

    # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼Œç”Ÿæˆæ€»ç»“
    if file_processed:
        file_processed = False
        summary_prompt = generate_summary(current_file_text)
        messages[-1]["content"] = summary_prompt
        assistant_generator = generate_text(summary_prompt)
    # å¤„ç†åŸºäºæ–‡ä»¶å†…å®¹çš„æé—®
    elif user_input.strip().lower().startswith("/file "):
        if not current_file_text:
            assistant_generator = iter(["è¯·å…ˆä¸Šä¼ æ–‡ä»¶"])
        else:
            content = user_input.strip()[6:]
            question = generate_question(current_file_text, content)
            assistant_generator = generate_text(question)
    # åˆ¤æ–­æ˜¯å¦æ˜¯æœç´¢æŒ‡ä»¤
    elif user_input.strip().lower().startswith("/search "):
        content = user_input.strip()[8:]
        try:
            enriched_query = search(content)
        except Exception as e:
            assistant_generator = iter([f"Search failed: {e}"])
        else:
            messages[-1]["content"] = enriched_query
            assistant_generator = chat(messages)  # æµå¼ç”Ÿæˆ
    # åˆ¤æ–­æ˜¯å¦æ˜¯ç½‘é¡µæ€»ç»“
    elif user_input.strip().lower().startswith("/fetch "):
        url = user_input.strip()[7:]
        try:
            question = fetch(url)
        except Exception as e:
            assistant_generator = iter([f"Fetch failed: {e}"])
        else:
            messages[-1]["content"] = question
            assistant_generator = chat(messages)  # æµå¼ç”Ÿæˆ
    # åˆ¤æ–­æ˜¯å¦æ˜¯å›¾ç‰‡ç”ŸæˆæŒ‡ä»¤
    elif isinstance(user_input, str) and user_input.strip().lower().startswith("/image "):
        image_prompt = user_input.strip()[7:].strip()
        if not image_prompt:
            # æ— æè¿°æ—¶ï¼šç•Œé¢æ˜¾ç¤ºæç¤ºæ–‡æœ¬ï¼Œmessagesè®°å½•æç¤ºæ–‡æœ¬
            response_text = "è¯·æä¾›å›¾ç‰‡æè¿°ï¼Œä¾‹å¦‚: /image a baby sea otter"
            assistant_generator = iter([response_text])
            # æ¨é€ç•Œé¢æ˜¾ç¤º
            partial_reply = ""
            for chunk in assistant_generator:
                partial_reply += chunk
                history[-1] = (user_input, partial_reply)
                yield history
            # æ›´æ–°messagesï¼ˆè®°å½•æç¤ºæ–‡æœ¬ï¼‰
            messages.append({"role": "assistant", "content": response_text})
            return
        else:
            try:
                image_url = image_generate(image_prompt)
                if image_url:
                    # ç•Œé¢æ˜¾ç¤ºï¼šå¸¦Markdownæ ¼å¼çš„å›¾ç‰‡
                    display_text = f"![ç”Ÿæˆçš„å›¾ç‰‡]({image_url})"
                    assistant_generator = iter([display_text])
                    # æ¨é€ç•Œé¢æ˜¾ç¤º
                    partial_reply = ""
                    for chunk in assistant_generator:
                        partial_reply += chunk
                        history[-1] = (user_input, partial_reply)
                        yield history
                    # é‡ç‚¹ï¼šmessagesè®°å½•çº¯URLï¼ˆç¬¦åˆè¦æ±‚æ ¼å¼ï¼‰
                    messages.append({"role": "assistant", "content": image_url})
                    return
                else:
                    # ç”Ÿæˆå¤±è´¥æ—¶ï¼šç•Œé¢å’Œmessageså‡è®°å½•å¤±è´¥æç¤º
                    response_text = "å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
                    assistant_generator = iter([response_text])
                    partial_reply = ""
                    for chunk in assistant_generator:
                        partial_reply += chunk
                        history[-1] = (user_input, partial_reply)
                        yield history
                    messages.append({"role": "assistant", "content": response_text})
                    return
            except Exception as e:
                error_text = f"å›¾ç‰‡ç”Ÿæˆé”™è¯¯: {str(e)}"
                assistant_generator = iter([error_text])
                partial_reply = ""
                for chunk in assistant_generator:
                    partial_reply += chunk
                    history[-1] = (user_input, partial_reply)
                    yield history
                messages.append({"role": "assistant", "content": error_text})
                return

    else:
        assistant_generator = chat(messages)      # æµå¼ç”Ÿæˆ

    partial_reply = "" # ç´¯ç§¯çš„å›å¤
    for chunk in assistant_generator:
        partial_reply += chunk
        history[-1] = (user_input, partial_reply)  # æ›¿æ¢æœ€åä¸€ä¸ªå…ƒç»„
        yield history                             # æ¯å¾—åˆ°æ–°å†…å®¹å°±æ¨é€
    
    #  messages æœ€ç»ˆåŒæ­¥ 
    messages.append({"role": "assistant", "content": partial_reply})


with gr.Blocks() as demo:
    chatbot = gr.Chatbot(
        [],
        elem_id="chatbot",
        avatar_images=(None, (os.path.join(os.path.dirname(__file__), "avatar.png"))),
    )

    with gr.Row():
        txt = gr.Textbox(
            scale=4,
            show_label=False,
            placeholder="Enter text and press enter, or upload an image",
            container=False,
        )
        clear_btn = gr.Button('Clear')
        btn = gr.UploadButton("ğŸ“", file_types=["image", "video", "audio", "text"])

    # æ–‡æœ¬è¾“å…¥åï¼Œå…ˆè°ƒç”¨ add_text æ›´æ–°æ¶ˆæ¯ï¼Œå†è°ƒç”¨ bot ç”Ÿæˆå›å¤ï¼Œæœ€åæ¢å¤è¾“å…¥æ¡†äº¤äº’çŠ¶æ€
    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(
        bot, chatbot, chatbot
    )
    txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)

    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(
        bot, chatbot, chatbot
    )

    # æ¸…é™¤æ¶ˆæ¯
    def clear_all():
        messages.clear()
        history.clear()
        global current_file_text
        current_file_text = ""
        return []  # chatbot expects a list of tuples like [(user, assistant), ...]

    clear_btn.click(clear_all, inputs=None, outputs=chatbot, queue=False)

demo.queue()
demo.launch()